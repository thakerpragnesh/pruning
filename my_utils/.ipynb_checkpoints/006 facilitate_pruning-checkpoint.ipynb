{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_utils.loadModel as lm\n",
    "import my_utils.initialize_pruning as ip\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = Tensor to be prune, n is ln normalization, dim dimension over which we want to perform \n",
    "def compute_distance_score(t, n=1, dim_to_keep=[0,1],threshold=1):\n",
    "        # dims = all axes, except for the one identified by `dim`        \n",
    "        dim_to_prune = list(range(t.dim()))   #initially it has all dims\n",
    "        #remove dim which we want to keep from dimstoprune\n",
    "        for i in range(len(dim_to_keep)):   \n",
    "            dim_to_prune.remove(dim_to_keep[i])\n",
    "        \n",
    "        size = t.shape\n",
    "        print(f\"\\nShape of the tensor: {size}\")\n",
    "        print(f\"Print the Dims we want to keep: {dim_to_keep}\")\n",
    "        \n",
    "        module_buffer = torch.zeros_like(t)\n",
    "                \n",
    "        #shape of norm should be equal to multiplication of dim to keep values\n",
    "        norm = torch.norm(t, p=n, dim=dim_to_prune)\n",
    "        print(f\"norm shape = {norm.shape}\")\n",
    "        size = t.shape\n",
    "        print(\"Number Of Features Map in current  layer l     =\",size[0])\n",
    "        print(\"Number Of Features Map in previous layer (l-1) =\",size[1])\n",
    "        \n",
    "        for i in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                module_buffer[i][j] = t[i][j]/norm[i][j]\n",
    "        \n",
    "        dist = torch.zeros(size[1],size[0],size[0])\n",
    "        \n",
    "        channelList = []\n",
    "        for j in range(size[1]):\n",
    "            idxtupple = []\n",
    "            print('.',end='')\n",
    "            for i1 in range(size[0]):\n",
    "                for i2 in range((i1+1),size[0]):\n",
    "                    dist[j][i1][i2] = torch.norm( (module_buffer[i1][j]-module_buffer[i2][j]) ,p=1)\n",
    "                    dist[j][i2][i1] = dist[j][i1][i2]\n",
    "                    \n",
    "                    if dist[j][i1][i2] < threshold:\n",
    "                        idxtupple.append([j,i1,i2,dist[j][i1][i2]])\n",
    "            channelList.append(idxtupple)\n",
    "        return channelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_kernel_by_distance(kernalList):\n",
    "    for i in range(len(kernalList)):\n",
    "        iListLen = len(kernalList[i])\n",
    "        #print(f'lemgth of list {i} ={iListLen}')\n",
    "        for j in range(iListLen):\n",
    "            for k in range(iListLen-j-1):\n",
    "                #print(f\"Value of i={i}     Value of j={j} Value of k={k}\")\n",
    "                if kernalList[i][k+1][3] < kernalList[i][k][3]:\n",
    "                    kernalList[i][k+1], kernalList[i][k] = kernalList[i][k], kernalList[i][k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_element(channel_list,k):\n",
    "    channel_k_list = []\n",
    "    for i in range(len(channel_list)):\n",
    "        tempList = []\n",
    "        for j in range(k):\n",
    "            tempList.append(channel_list[i][j])\n",
    "        channel_k_list.append(tempList)\n",
    "    return channel_k_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90144ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = Tensor to be prune, n is ln normalization, dim dimension over which we want to perform \n",
    "def compute_kernal_score(t, n=1, dim_to_keep=[0,1],threshold=1):\n",
    "        # dims = all axes, except for the one identified by `dim`        \n",
    "        dim_to_prune = list(range(t.dim()))   #initially it has all dims\n",
    "        \n",
    "        #remove dim which we want to keep from dimstoprune\n",
    "        for i in range(len(dim_to_keep)):   \n",
    "            dim_to_prune.remove(dim_to_keep[i])\n",
    "        \n",
    "        size = t.shape\n",
    "        print(size)\n",
    "        print(dim_to_keep)\n",
    "        \n",
    "        module_buffer = torch.zeros_like(t)\n",
    "        #sshape of norm should be equal to multiplication of dim to keep values\n",
    "        norm = torch.norm(t, p=n, dim=dim_to_prune)\n",
    "        kernelList = []\n",
    "        size = norm.shape\n",
    "        for i in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                kernelList.append([i,j,norm[i][j]])\n",
    "            \n",
    "        return kernelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_kernel_by_value(kernelList):\n",
    "    return kernelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayLayer(channelTupple):\n",
    "    for i in range(len(channelTupple)):\n",
    "        for j in range(len(channelTupple[i])):\n",
    "            if j%3==0:\n",
    "                print()\n",
    "            print(channelTupple[i][j],'\\t',end='')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vgg16'\n",
    "model = lm.load_model(model_name=model_name,number_of_class=6,pretrainval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d368b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = ip.getBlockList(modelname=model_name)\n",
    "feature_list = ip.getFeatureList(modelname=model_name)\n",
    "module = ip.getPruneModule(model,prunelist=feature_list)\n",
    "prune_count = ip.getPruneCount(module=module,blocks=blocks,maxpr=0.25)\n",
    "print(f\"blocks            = {blocks} \\n\"\n",
    "      f\"feature list      = {feature_list} \\n\"\n",
    "      f\"prune count list  = {prune_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "channelTuppleList = []\n",
    "st =2\n",
    "en = 4\n",
    "for i in range(st,en):\n",
    "    channelTuppleList.append(_compute_distance_score(module[i]._parameters['weight'],threshold=1))\n",
    "print(\"\\n\\n\\nHere is the :\",len(channelTuppleList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677afd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(channelTuppleList)):\n",
    "    for j in range(len(channelTuppleList[i])):\n",
    "        print(f\"\\n\\nlength of list: {len(channelTuppleList[i][j])} and \"\n",
    "              f\"1st 3 ele are\\n{(channelTuppleList[i][j][0:3])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeeed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(channelTuppleList)):\n",
    "    sortKernalByDistance(channelTuppleList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e032055",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(channelTuppleList)):\n",
    "    for j in range(len(channelTuppleList[i])):\n",
    "        print(f\"\\n\\nlength of list: {len(channelTuppleList[i][j])} and 1st 3 ele are\\n{(channelTuppleList[i][j][0:3])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(channelTuppleList)):\n",
    "    print(\"\\n\\nRow :\",i)\n",
    "    for j in range(3):\n",
    "        for k in range(len(channelTuppleList[i][j])):\n",
    "            print(channelTuppleList[i][j][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "newList = []\n",
    "for i in range(len(channelTuppleList)):\n",
    "    newList.append(get_k_element(channel_list=channelTuppleList[i],k=prune_count[i]) )\n",
    "\n",
    "for i in range(len(newList)):\n",
    "    print(f\"\\n\\n\\nlenth of list: {len(newList[i])}\")\n",
    "    for j in range(len(newList[i])):\n",
    "        \n",
    "        for k in range(len(newList[i][j])):\n",
    "            print(newList[i][j][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0259dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(channelTuppleList)):\n",
    "    print(\"\\n**************************************************************************************************************************\")\n",
    "    displayLayer(channelTuppleList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668c9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
