{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch library to build neural network\n",
    "import torch  # Elementory function of tensor is define in torch package\n",
    "import torch.nn as nn # Several layer architectur is define here\n",
    "import torch.nn.functional as F # loss function and activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computer vision is one of the most important application and thus lots \n",
    "of deplopment in the and torch.vision provides many facilities that can \n",
    "be use to imporve model such as data augmentation, reading data batchwise, \n",
    "suffling data before each epoch and many more\n",
    "\"\"\"\n",
    "# import torch library related to image data processing\n",
    "import torchvision # provides facilities to access image dataset\n",
    "from torchvision.datasets.utils import download_url \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "def ensure_dir(dir_path):\n",
    "    directory = os.path.dirname(dir_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It takes location of dataset, selected dataset, name of train and test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Input ###############################\n",
    "def setFolderLocation(datasets, selectedDataset='', train='train', test='test'):\n",
    "    global dataset_location \n",
    "    global selected_dataset \n",
    "    global train_directory \n",
    "    global test_directory \n",
    "    global data_dir \n",
    "    global zipFile\n",
    "    \n",
    "    dataset_location = datasets    #'/home/pragnesh/Dataset/'\n",
    "    selected_dataset = selectedDataset\n",
    "    train_directory = train\n",
    "    test_directory = test\n",
    "    data_dir = dataset_location+selected_dataset\n",
    "    # zipFile = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Prepration\n",
    "\"\"\"\n",
    "Based on the image size of the dataset choose apropriate values of the color channel and Image Size\n",
    "\n",
    "Here we can define path to a folder where we can keep all the dataset. \n",
    "In the following we are using the zip files. Originally dataset should \n",
    "be in the following format DataSetName is parent folder and it should \n",
    "contain train and test folder. train and test folder should contain \n",
    "folder for each category and images of respective category should be in \n",
    "the respective category folder\n",
    "\"\"\"\n",
    "######################### Data Loading #########################################\n",
    "def extractData(dest_location):\n",
    "  fullpath = data_dir+'.zip'\n",
    "  zip_ref = zipfile.ZipFile(fullpath, 'r') #Opens the zip file in read mode\n",
    "  zip_ref.extractall(dest_location) #Extracts the files into the /tmp folder\n",
    "  data_dir = dest_location+'/IntelIC'\n",
    "  test_directory ='val'\n",
    "  zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Choose an apropriate batch size that can be loaded in the current \n",
    "enviroment without crashing and also do not choose too big batch even \n",
    "if dataset is small because it leads to very few updates per epoch\n",
    "\"\"\"\n",
    "#################### Create Batch Of Dataset and do data augmentation ###########\n",
    "batch_size = 16\n",
    "image_size = 224\n",
    "def setBatchSize(batch_size_l=32):\n",
    "    batch_size = batch_size_l\n",
    "    \n",
    "def setImageSize(image_sizeLocal=224):\n",
    "    global image_size\n",
    "    image_size = image_sizeLocal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader():\n",
    "    \n",
    "    \"\"\"\n",
    "    Data Augmentaion generally help in reducing overfitting error during \n",
    "    trainng process and thus we are performing randon horizontal flip and \n",
    "    random crop during training but during validation as no training happens \n",
    "    we dont perform data augmentation\n",
    "    \"\"\"\n",
    "    # Data augmentation and normalization for training\n",
    "    # Just normalization for validation\n",
    "    data_transforms = {\n",
    "        train_directory: transforms.Compose([\n",
    "            transforms.RandomResizedCrop(image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        test_directory: transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                              data_transforms[x])\n",
    "                      for x in [train_directory, test_directory]}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                                 shuffle=True, num_workers=1)\n",
    "                  for x in [train_directory, test_directory]}\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in [train_directory, test_directory]}\n",
    "    class_names = image_datasets[train_directory].classes\n",
    "    return dataloaders, data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoaderEval():\n",
    "    \n",
    "    \"\"\"\n",
    "    Data Augmentaion generally help in reducing overfitting error during \n",
    "    trainng process and thus we are performing randon horizontal flip and \n",
    "    random crop during training but during validation as no training happens \n",
    "    we dont perform data augmentation\n",
    "    \"\"\"\n",
    "    # Data augmentation and normalization for training\n",
    "    # Just normalization for validation\n",
    "    data_transforms = {\n",
    "        train_directory: transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop,\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        test_directory: transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                              data_transforms[x])\n",
    "                      for x in [train_directory, test_directory]}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                                 shuffle=True, num_workers=1)\n",
    "                  for x in [train_directory, test_directory]}\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in [train_directory, test_directory]}\n",
    "    class_names = image_datasets[train_directory].classes\n",
    "    return dataloaders, data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
